{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **ðŸ” Predicting ICD-9 Codes from Clinical Notes with Deep Neural Networks**\n",
    "\n",
    "## **Dataset:** MIMIC-III\n",
    "The **MIMIC-III** dataset provides an extensive collection of de-identified clinical data, ideal for building predictive models. In this project, we aim to **predict ICD-9 codes** from **clinical notes** using **deep neural networks**.\n",
    "\n",
    "### **Project Objective**\n",
    "The primary objective of this project is to leverage **deep learning** for accurately predicting **ICD-9 codes**, which are essential for categorizing diseases and medical conditions in healthcare settings. Using the MIMIC-III dataset, we can build a robust model with significant potential for real-world applications.\n",
    "\n",
    "### **Approach**\n",
    "1. **Data Preprocessing**: Clean and tokenize the clinical notes.\n",
    "2. **Model Architecture**: Employ a **deep neural network** to capture patterns in textual data.\n",
    "3. **Training and Evaluation**: Train the model on MIMIC-III and assess performance metrics.\n",
    "\n",
    "---\n",
    "\n",
    "> **Note**: This project is focused on exploring **natural language processing (NLP)** techniques and **deep learning frameworks** like **TensorFlow** and **PyTorch**.\n",
    "\n",
    "### **Let's dive in! ðŸš€**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocssing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\netra\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\netra\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\netra\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Collecting pickle5\n",
      "  Using cached pickle5-0.0.11.tar.gz (132 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\netra\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\netra\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\netra\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\netra\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\netra\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\netra\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\netra\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\netra\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\netra\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Building wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py): started\n",
      "  Building wheel for pickle5 (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pickle5\n",
      "Failed to build pickle5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— python setup.py bdist_wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [17 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-311\n",
      "      creating build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      creating build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      running build_ext\n",
      "      building 'pickle5._pickle' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pickle5\n",
      "ERROR: Could not build wheels for pickle5, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy pandas nltk pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NETRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NETRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stopwords and punkt tokenizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES = pd.read_csv(r'D:\\Final_year_project\\final project dataset\\final project\\NOTEEVENTS-2.csv\\NOTEEVENTS-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_ICD_DIAG = pd.read_csv(r'D:\\Final_year_project\\final project dataset\\final project\\DIAGNOSES_ICD.xlsx - DIAGNOSES_ICD.xlsx.csv')\n",
    "D_ICD_PROC = pd.read_csv(r'D:\\Final_year_project\\final project dataset\\final project\\PROCEDURES_ICD.xlsx - PROCEDURES_ICD.xlsx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_icd = pd.read_csv(r'D:\\Final_year_project\\final project dataset\\final project\\DIAGNOSES_ICD.xlsx - DIAGNOSES_ICD.xlsx.csv')\n",
    "procedures_icd = pd.read_csv(r'D:\\Final_year_project\\final project dataset\\final project\\PROCEDURES_ICD.xlsx - PROCEDURES_ICD.xlsx.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering:-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES.columns=NOTES.columns.str.upper()\n",
    "D_ICD_DIAG.columns=D_ICD_DIAG.columns.str.upper()\n",
    "D_ICD_PROC.columns=D_ICD_PROC.columns.str.upper()\n",
    "diagnoses_icd.columns=diagnoses_icd.columns.str.upper()\n",
    "procedures_icd.columns=procedures_icd.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SEQ_NUM</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1297</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1301</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651042</th>\n",
       "      <td>639798</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651043</th>\n",
       "      <td>639799</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651044</th>\n",
       "      <td>639800</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>4.0</td>\n",
       "      <td>V1279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651045</th>\n",
       "      <td>639801</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651046</th>\n",
       "      <td>639802</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651047 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
       "0         1297         109   172335      1.0     40301\n",
       "1         1298         109   172335      2.0       486\n",
       "2         1299         109   172335      3.0     58281\n",
       "3         1300         109   172335      4.0      5855\n",
       "4         1301         109   172335      5.0      4254\n",
       "...        ...         ...      ...      ...       ...\n",
       "651042  639798       97503   188195      2.0     20280\n",
       "651043  639799       97503   188195      3.0     V5869\n",
       "651044  639800       97503   188195      4.0     V1279\n",
       "651045  639801       97503   188195      5.0      5275\n",
       "651046  639802       97503   188195      6.0      5569\n",
       "\n",
       "[651047 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnoses_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP = NOTES[['HADM_ID','CATEGORY','TEXT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6947"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diagnoses_icd['ICD9_CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188442.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2183-9-25**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193793.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2184-1-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118446.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2103-4-11**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157985.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2103-10-7**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189488.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2131-4-2**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083175</th>\n",
       "      <td>186787.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2198-5-31**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083176</th>\n",
       "      <td>156868.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2168-12-29**]     Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083177</th>\n",
       "      <td>156868.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2168-12-29**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083178</th>\n",
       "      <td>156868.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2168-12-29**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083179</th>\n",
       "      <td>188442.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date: [**2183-9-25**]          Disch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083180 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          HADM_ID           CATEGORY  \\\n",
       "0        188442.0  Discharge summary   \n",
       "1        193793.0  Discharge summary   \n",
       "2        118446.0  Discharge summary   \n",
       "3        157985.0  Discharge summary   \n",
       "4        189488.0  Discharge summary   \n",
       "...           ...                ...   \n",
       "2083175  186787.0  Discharge summary   \n",
       "2083176  156868.0  Discharge summary   \n",
       "2083177  156868.0  Discharge summary   \n",
       "2083178  156868.0  Discharge summary   \n",
       "2083179  188442.0  Discharge summary   \n",
       "\n",
       "                                                      TEXT  \n",
       "0        Admission Date:  [**2183-9-25**]       Dischar...  \n",
       "1        Admission Date:  [**2184-1-16**]       Dischar...  \n",
       "2        Admission Date:  [**2103-4-11**]              ...  \n",
       "3        Admission Date:  [**2103-10-7**]       Dischar...  \n",
       "4        Admission Date:  [**2131-4-2**]              D...  \n",
       "...                                                    ...  \n",
       "2083175  Admission Date:  [**2198-5-31**]              ...  \n",
       "2083176  Admission Date:  [**2168-12-29**]     Discharg...  \n",
       "2083177  Admission Date:  [**2168-12-29**]       Discha...  \n",
       "2083178  Admission Date:  [**2168-12-29**]       Discha...  \n",
       "2083179  Admission Date: [**2183-9-25**]          Disch...  \n",
       "\n",
       "[2083180 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP = KEEP.groupby(['HADM_ID']).agg({'TEXT': ' '.join, 'CATEGORY': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HADM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001.0</th>\n",
       "      <td>Admission Date:  [**2117-9-11**]              ...</td>\n",
       "      <td>Discharge summary Radiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003.0</th>\n",
       "      <td>Admission Date:  [**2150-4-17**]              ...</td>\n",
       "      <td>Discharge summary Echo ECG Nursing Nursing Phy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006.0</th>\n",
       "      <td>Admission Date:  [**2108-4-6**]       Discharg...</td>\n",
       "      <td>Discharge summary Discharge summary Echo ECG R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007.0</th>\n",
       "      <td>Admission Date:  [**2145-3-31**]              ...</td>\n",
       "      <td>Discharge summary ECG Nursing/other Nursing/ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009.0</th>\n",
       "      <td>Admission Date:  [**2162-5-16**]              ...</td>\n",
       "      <td>Discharge summary Echo ECG Radiology Radiology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993.0</th>\n",
       "      <td>Admission Date:  [**2161-10-23**]       Discha...</td>\n",
       "      <td>Discharge summary ECG ECG ECG ECG ECG ECG Radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994.0</th>\n",
       "      <td>Admission Date:  [**2188-7-7**]       Discharg...</td>\n",
       "      <td>Discharge summary ECG Radiology Radiology Radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995.0</th>\n",
       "      <td>Admission Date: [**2137-12-11**]        Discha...</td>\n",
       "      <td>Discharge summary Echo ECG ECG ECG ECG ECG Rad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998.0</th>\n",
       "      <td>Admission Date:  [**2119-2-18**]              ...</td>\n",
       "      <td>Discharge summary Echo ECG ECG Radiology Radio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999.0</th>\n",
       "      <td>Admission Date:  [**2136-4-4**]              D...</td>\n",
       "      <td>Discharge summary ECG ECG ECG Radiology Radiol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58361 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       TEXT  \\\n",
       "HADM_ID                                                       \n",
       "100001.0  Admission Date:  [**2117-9-11**]              ...   \n",
       "100003.0  Admission Date:  [**2150-4-17**]              ...   \n",
       "100006.0  Admission Date:  [**2108-4-6**]       Discharg...   \n",
       "100007.0  Admission Date:  [**2145-3-31**]              ...   \n",
       "100009.0  Admission Date:  [**2162-5-16**]              ...   \n",
       "...                                                     ...   \n",
       "199993.0  Admission Date:  [**2161-10-23**]       Discha...   \n",
       "199994.0  Admission Date:  [**2188-7-7**]       Discharg...   \n",
       "199995.0  Admission Date: [**2137-12-11**]        Discha...   \n",
       "199998.0  Admission Date:  [**2119-2-18**]              ...   \n",
       "199999.0  Admission Date:  [**2136-4-4**]              D...   \n",
       "\n",
       "                                                   CATEGORY  \n",
       "HADM_ID                                                      \n",
       "100001.0                        Discharge summary Radiology  \n",
       "100003.0  Discharge summary Echo ECG Nursing Nursing Phy...  \n",
       "100006.0  Discharge summary Discharge summary Echo ECG R...  \n",
       "100007.0  Discharge summary ECG Nursing/other Nursing/ot...  \n",
       "100009.0  Discharge summary Echo ECG Radiology Radiology...  \n",
       "...                                                     ...  \n",
       "199993.0  Discharge summary ECG ECG ECG ECG ECG ECG Radi...  \n",
       "199994.0  Discharge summary ECG Radiology Radiology Radi...  \n",
       "199995.0  Discharge summary Echo ECG ECG ECG ECG ECG Rad...  \n",
       "199998.0  Discharge summary Echo ECG ECG Radiology Radio...  \n",
       "199999.0  Discharge summary ECG ECG ECG Radiology Radiol...  \n",
       "\n",
       "[58361 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HADM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001.0</th>\n",
       "      <td>Admission Date:  [**2117-9-11**]              ...</td>\n",
       "      <td>Discharge summary Radiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003.0</th>\n",
       "      <td>Admission Date:  [**2150-4-17**]              ...</td>\n",
       "      <td>Discharge summary Echo ECG Nursing Nursing Phy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006.0</th>\n",
       "      <td>Admission Date:  [**2108-4-6**]       Discharg...</td>\n",
       "      <td>Discharge summary Discharge summary Echo ECG R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007.0</th>\n",
       "      <td>Admission Date:  [**2145-3-31**]              ...</td>\n",
       "      <td>Discharge summary ECG Nursing/other Nursing/ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009.0</th>\n",
       "      <td>Admission Date:  [**2162-5-16**]              ...</td>\n",
       "      <td>Discharge summary Echo ECG Radiology Radiology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993.0</th>\n",
       "      <td>Admission Date:  [**2161-10-23**]       Discha...</td>\n",
       "      <td>Discharge summary ECG ECG ECG ECG ECG ECG Radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994.0</th>\n",
       "      <td>Admission Date:  [**2188-7-7**]       Discharg...</td>\n",
       "      <td>Discharge summary ECG Radiology Radiology Radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995.0</th>\n",
       "      <td>Admission Date: [**2137-12-11**]        Discha...</td>\n",
       "      <td>Discharge summary Echo ECG ECG ECG ECG ECG Rad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998.0</th>\n",
       "      <td>Admission Date:  [**2119-2-18**]              ...</td>\n",
       "      <td>Discharge summary Echo ECG ECG Radiology Radio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999.0</th>\n",
       "      <td>Admission Date:  [**2136-4-4**]              D...</td>\n",
       "      <td>Discharge summary ECG ECG ECG Radiology Radiol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58361 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       TEXT  \\\n",
       "HADM_ID                                                       \n",
       "100001.0  Admission Date:  [**2117-9-11**]              ...   \n",
       "100003.0  Admission Date:  [**2150-4-17**]              ...   \n",
       "100006.0  Admission Date:  [**2108-4-6**]       Discharg...   \n",
       "100007.0  Admission Date:  [**2145-3-31**]              ...   \n",
       "100009.0  Admission Date:  [**2162-5-16**]              ...   \n",
       "...                                                     ...   \n",
       "199993.0  Admission Date:  [**2161-10-23**]       Discha...   \n",
       "199994.0  Admission Date:  [**2188-7-7**]       Discharg...   \n",
       "199995.0  Admission Date: [**2137-12-11**]        Discha...   \n",
       "199998.0  Admission Date:  [**2119-2-18**]              ...   \n",
       "199999.0  Admission Date:  [**2136-4-4**]              D...   \n",
       "\n",
       "                                                   CATEGORY  \n",
       "HADM_ID                                                      \n",
       "100001.0                        Discharge summary Radiology  \n",
       "100003.0  Discharge summary Echo ECG Nursing Nursing Phy...  \n",
       "100006.0  Discharge summary Discharge summary Echo ECG R...  \n",
       "100007.0  Discharge summary ECG Nursing/other Nursing/ot...  \n",
       "100009.0  Discharge summary Echo ECG Radiology Radiology...  \n",
       "...                                                     ...  \n",
       "199993.0  Discharge summary ECG ECG ECG ECG ECG ECG Radi...  \n",
       "199994.0  Discharge summary ECG Radiology Radiology Radi...  \n",
       "199995.0  Discharge summary Echo ECG ECG ECG ECG ECG Rad...  \n",
       "199998.0  Discharge summary Echo ECG ECG Radiology Radio...  \n",
       "199999.0  Discharge summary ECG ECG ECG Radiology Radiol...  \n",
       "\n",
       "[58361 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HADM_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\NETRA\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HADM_ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(KEEP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHADM_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[1;32mc:\\Users\\NETRA\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\NETRA\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HADM_ID'"
     ]
    }
   ],
   "source": [
    "len(KEEP['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP.to_csv('KEEP.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_dict = {}\n",
    "for i in range(len(diagnoses_icd)):\n",
    "    entry = diagnoses_icd.iloc[i]\n",
    "    hadm = entry['HADM_ID']\n",
    "    icd = entry['ICD9_CODE']\n",
    "    if hadm not in diagnoses_dict:\n",
    "        diagnoses_dict[hadm] = [icd]\n",
    "    else:\n",
    "        diagnoses_dict[hadm].append(icd)\n",
    "        \n",
    "procedures_dict = {}\n",
    "for i in range(len(procedures_icd)):\n",
    "    entry = procedures_icd.iloc[i]\n",
    "    hadm = entry['HADM_ID']\n",
    "    icd = entry['ICD9_CODE']\n",
    "    if hadm not in procedures_dict:\n",
    "        procedures_dict[hadm] = [icd]\n",
    "    else:\n",
    "        procedures_dict[hadm].append(icd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df = pd.DataFrame.from_dict(diagnoses_dict,orient='index')\n",
    "procedures_df = pd.DataFrame.from_dict(procedures_dict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df.columns = ['DIAG_CODE'+str(i) for i in range(1,len(diagnoses_df.columns)+1)]\n",
    "diagnoses_df.index.name = 'HADM_ID'\n",
    "procedures_df.columns = ['PRCD_CODE'+str(i) for i in range(1,len(procedures_df.columns)+1)]\n",
    "procedures_df.index.name = 'HADM_ID'\n",
    "codes_df = pd.merge(diagnoses_df, procedures_df, how='outer', on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df['DIAG_CODES'] = diagnoses_df[diagnoses_df.columns[:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "procedures_df['PROC_CODES'] = procedures_df[procedures_df.columns[:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = diagnoses_df[['DIAG_CODES']]\n",
    "procedures = procedures_df[['PROC_CODES']]\n",
    "codes = pd.merge(diagnoses, procedures, how='outer', on='HADM_ID')\n",
    "codes = codes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.to_csv('CODES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP.set_index('HADM_ID')\n",
    "merged_df = pd.merge(KEEP, codes, how='left', on='HADM_ID')\n",
    "merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = merged_df.sample(n=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE.to_csv('SAMPLE_20K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Codes to Dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = SAMPLE.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_diag = diagnoses_icd[diagnoses_icd['HADM_ID'].isin(sample_ids)]\n",
    "flt_proc = procedures_icd[procedures_icd['HADM_ID'].isin(sample_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_keep = flt_diag['ICD9_CODE'].value_counts()[:300]\n",
    "proc_keep = flt_proc['ICD9_CODE'].value_counts()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2idx, idx2diag = {},{}\n",
    "for d in diag_keep.index:\n",
    "    if d not in diag2idx:\n",
    "        idx2diag[len(idx2diag)] = d\n",
    "        diag2idx[d] = len(diag2idx)\n",
    "        \n",
    "proc2idx, idx2proc = {},{}\n",
    "for p in proc_keep.index:\n",
    "    if p not in proc2idx:\n",
    "        idx2proc[len(idx2proc)] = p\n",
    "        proc2idx[p] = len(proc2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('diag2idx.pickle','wb') as f:\n",
    "    pickle.dump(diag2idx,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('idx2diag.pickle','wb') as f:\n",
    "    pickle.dump(idx2diag,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('proc2idx.pickle','wb') as f:\n",
    "    pickle.dump(proc2idx,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('idx2proc.pickle','wb') as f:\n",
    "    pickle.dump(idx2proc,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT CODE LIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_code2idx(org_lst):\n",
    "    coded_lst = []\n",
    "    for c in org_lst.split(','):\n",
    "        if c in diag2idx:\n",
    "            coded_lst.append(diag2idx[c])\n",
    "    return coded_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_code2idx(org_lst):\n",
    "    coded_lst = []\n",
    "    for c in org_lst.split(','):\n",
    "        c_ = int(str(c).split('.')[0])\n",
    "        if c_ in proc2idx:\n",
    "            coded_lst.append(proc2idx[c_])\n",
    "            \n",
    "    return coded_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE['CODED_DIAG'] = SAMPLE['DIAG_CODES'].apply(diag_code2idx)\n",
    "SAMPLE['CODED_PROC'] = SAMPLE['PROC_CODES'].apply(proc_code2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **General processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text): \n",
    "        stop_words = set(stopwords.words(\"english\")) \n",
    "        word_tokens = word_tokenize(text) \n",
    "        filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "        return filtered_text \n",
    "    \n",
    "def preprocess(note):\n",
    "    note = note.replace('\\n',' ')\n",
    "    note = note.replace('w/', 'with')\n",
    "    note = note.lower() #lower case\n",
    "    note = re.sub(r'\\d+', '', note) #remove numbers\n",
    "    note = note.translate(str.maketrans('', '', string.punctuation)) #remove punctuation\n",
    "    note = \" \".join(note.split())\n",
    "    note = remove_stopwords(note)\n",
    "    return note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1k_removed['NOTE'] = sample_1k_removed['TEXT'].apply(preprocess)\n",
    "sample_10k_removed['NOTE'] = sample_10k_removed['TEXT'].apply(preprocess)\n",
    "merged_df_removed['NOTE'] = merged_df_removed['TEXT'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE['NOTE'] = SAMPLE['TEXT'].apply(preprocess)\n",
    "SAMPLE['NOTE'] = SAMPLE['TEXT'].apply(preprocess)\n",
    "merged_df['NOTE'] = merged_df['TEXT'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1k_cleaned = sample_1k_removed[['NOTE','CODED_DIAG','CODED_PROC']]\n",
    "sample_10k_cleaned = sample_10k_removed[['NOTE','CODED_DIAG','CODED_PROC']]\n",
    "merged_df_cleaned = merged_df_removed[['NOTE','CODED_DIAG','CODED_PROC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1k_removed['CODED_NOTE'] = sample_1k_cleaned['NOTE']\n",
    "sample_10k_removed['CODED_NOTE'] = sample_10k_cleaned['NOTE']\n",
    "merged_df_removed['CODED_NOTE'] = merged_df_cleaned['NOTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10k_removed.to_csv('SAMPLE10K_ALL.csv')\n",
    "sample_1k_removed.to_csv('SAMPLE1K_ALL.csv')\n",
    "merged_df_removed.to_csv('ALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_20k = merged_df_removed.sample(n = 20000) \n",
    "sample_20k.to_csv('SAMPLE20K_ALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_20k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = pd.read_csv('19908_all_coded_token.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "for i, s in enumerate(SAMPLE['NOTE']):\n",
    "    for w in s:\n",
    "        corpus[w] = corpus.get(w, 1) + 1\n",
    "corpus = {k: v for k, v in sorted(corpus.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_slice = dict(itertools.islice(corpus.items(), 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **build dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word2idx = {'<PAD>': 0, '<UNK>':1}\n",
    "idx2word = {0: '<PAD>', 1:'<UNK>'}\n",
    "for c in corpus_slice:\n",
    "    word2idx[c] = len(word2idx)\n",
    "    idx2word[len(idx2word)] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note2idx(org_lst):\n",
    "    coded_lst = []\n",
    "    for w in org_lst:\n",
    "        if w in word2idx:\n",
    "            coded_lst.append(word2idx[w])\n",
    "        else:\n",
    "            coded_lst.append(0)\n",
    "    return coded_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note2idx_cap400(org_lst):\n",
    "    coded_lst = []\n",
    "    for w in org_lst:\n",
    "        if len(coded_lst) < 400 and w in word2idx:\n",
    "            coded_lst.append(word2idx[w])\n",
    "        else:\n",
    "            coded_lst.append(1)\n",
    "    coded_lst += [0]*(400-len(coded_lst))\n",
    "    return coded_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_20k['CODED_NOTE'] = sample_20k['NOTE'].apply(note2idx_cap400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_20k.to_csv('SAMPLE_2OK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1k_cleaned['NOTE'] = sample_1k_cleaned['NOTE'].apply(note2idx)\n",
    "sample_10k_cleaned['NOTE'] = sample_10k_cleaned['NOTE'].apply(note2idx)\n",
    "merged_df_cleaned['NOTE'] = merged_df_cleaned['NOTE'].apply(note2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10k_cleaned.to_csv('SAMPLE10K.csv')\n",
    "sample_1k_cleaned.to_csv('SAMPLE1K.csv')\n",
    "merged_df_cleaned.to_csv('CLEANED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_lst = [diag2idx, idx2diag, proc2idx, idx2proc, word2idx, idx2word]\n",
    "with open('diag2idx.pickle','wb') as f:\n",
    "    pickle.dump(diag2idx,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('idx2diag.pickle','wb') as f:\n",
    "    pickle.dump(idx2diag,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('proc2idx.pickle','wb') as f:\n",
    "    pickle.dump(proc2idx,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('idx2proc.pickle','wb') as f:\n",
    "    pickle.dump(idx2proc,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('word2idx.pickle','wb') as f:\n",
    "    pickle.dump(word2idx,f,pickle.HIGHEST_PROTOCOL)\n",
    "with open('idx2word.pickle','wb') as f:\n",
    "    pickle.dump(idx2word,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.pickle','wb') as f:\n",
    "    pickle.dump(corpus,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_icd[diagnoses_icd['HADM_ID']==172335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_dict = {}\n",
    "for i in range(len(diagnoses_icd)):\n",
    "    entry = diagnoses_icd.iloc[i]\n",
    "    hadm = entry['HADM_ID']\n",
    "    icd = entry['ICD9_CODE']\n",
    "    if hadm not in diagnoses_dict:\n",
    "        diagnoses_dict[hadm] = [icd]\n",
    "    else:\n",
    "        diagnoses_dict[hadm].append(icd)\n",
    "        \n",
    "procedures_dict = {}\n",
    "for i in range(len(procedures_icd)):\n",
    "    entry = procedures_icd.iloc[i]\n",
    "    hadm = entry['HADM_ID']\n",
    "    icd = entry['ICD9_CODE']\n",
    "    if hadm not in procedures_dict:\n",
    "        procedures_dict[hadm] = [icd]\n",
    "    else:\n",
    "        procedures_dict[hadm].append(icd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df = pd.DataFrame.from_dict(diagnoses_dict,orient='index')\n",
    "procedures_df = pd.DataFrame.from_dict(procedures_dict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df.columns = ['DIAG_CODE'+str(i) for i in range(1,len(diagnoses_df.columns)+1)]\n",
    "diagnoses_df.index.name = 'HADM_ID'\n",
    "procedures_df.columns = ['PRCD_CODE'+str(i) for i in range(1,len(procedures_df.columns)+1)]\n",
    "procedures_df.index.name = 'HADM_ID'\n",
    "codes_df = pd.merge(diagnoses_df, procedures_df, how='outer', on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df['DIAG_CODES'] = diagnoses_df[diagnoses_df.columns[:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "procedures_df['PROC_CODES'] = procedures_df[procedures_df.columns[:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = diagnoses_df[['DIAG_CODES']]\n",
    "procedures = procedures_df[['PROC_CODES']]\n",
    "codes = pd.merge(diagnoses, procedures, how='outer', on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df.to_csv('DIAGNOSES_DF.csv')\n",
    "procedures_df.to_csv('PROCEDURES_DF.csv')\n",
    "codes_df.to_csv('CODES_DF.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.to_csv('CODES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_csv(r'D:\\ICD9CodePredectionUsingMIMICDatasets\\data\\NOTEEVENTS.csv')\n",
    "notes_df = notes[['HADM_ID','TEXT']]\n",
    "notes_df.set_index('HADM_ID')\n",
    "merged_df = pd.merge(notes_df, codes, how='left', on='HADM_ID')\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df.to_csv('FULL_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SLICE NOTE\n",
    "sample_1k = merged_df.sample(n = 1000) \n",
    "sample_1k.to_csv('SAMPLE1K.csv')\n",
    "sample_10k = merged_df.sample(n = 10000) \n",
    "sample_10k.to_csv('SAMPLE10K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes['CATEGORY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'test a b c'\n",
    "b = ('aaa', 'bbb', 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.startswith(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Go to deidentify information** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_data['TEXT'] = full_data['TEXT'].replace(to_replace=r\"\\[.*?\\]\", value=\"\", regex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
